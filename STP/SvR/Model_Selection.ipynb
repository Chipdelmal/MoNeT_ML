{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from joblib import dump\n",
    "\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline_multioutput():\n",
    "    \"\"\"\n",
    "    Class which implements the usage of a single pipeline with \n",
    "    one estimator on scikit-learn's MultioutputClassifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            estimator(sklearn estimator): Estimator on which the pipeline will be\n",
    "                                done\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.fit_done = False\n",
    "    \n",
    "    def set_params(self,params,njobs=-1):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function which will set the class' estimator with the multioutput classifier.\n",
    "        ----------------------------------------------------------\n",
    "        Params:\n",
    "            params (dict): Parameters for the class' estimator.\n",
    "            njobs (int): The number of jobs to run in parallel.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        clf = self.estimator(**self.params)\n",
    "        m_clf = MultiOutputClassifier(clf)\n",
    "        self.classifier = m_clf\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        \"\"\"\n",
    "        Function which will fit the estimator with the multioutput classifier\n",
    "        in which X is the input and y is the desired output.\n",
    "        If no parameters had been set before (by using self.set_params)\n",
    "        the default parameters for the estimator will be set.\n",
    "        ----------------------------------------------------------\n",
    "        Params:\n",
    "            X (array): Input Data.\n",
    "            Y (array): Target value.\n",
    "            \n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.classifier\n",
    "        except Exception:\n",
    "            try:\n",
    "                clf = self.estimator()\n",
    "                m_clf = MultiOutputClassifier(clf)\n",
    "                self.classifier = m_clf\n",
    "            except Exception:\n",
    "                raise Exception('Parameters for {} must be set before'.format(self.estimator))\n",
    "        \n",
    "        self.classifier.fit(X_train,y_train)\n",
    "        self.fit_done = True\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        Predict multi-output variable using a model trained.\n",
    "        ------------------------------------------------------\n",
    "        Params:\n",
    "            X(array): Input Data.\n",
    "        Returns:\n",
    "            (array): Predicted values.\n",
    "        \"\"\"\n",
    "        if not self.fit_done:\n",
    "            raise Exception('The model has not been fitted.')\n",
    "        return self.classifier.predict(X)\n",
    "    \n",
    "    def score(self,X,y,verbose=False):\n",
    "        \"\"\"\n",
    "        Scoring for the model.\n",
    "        -------------------------------\n",
    "        Params:\n",
    "            X (array): Input Data.\n",
    "            Y (array): Target value.\n",
    "            verbose(bool): If set True, each score will be shown.\n",
    "        Returns:\n",
    "            scores(tuple): Accuracy, F1-score, Recall and Precision\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        ac = accuracy_score(y_pred,y)\n",
    "        f1 = f1_score(y_pred,y,average='micro')\n",
    "        rec = recall_score(y_pred,y,average='micro')\n",
    "        prec = precision_score(y_pred,y,average='micro')\n",
    "        if verbose:\n",
    "            print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n",
    "        \n",
    "        scores = {'accuracy':ac,'f1':f1,'recall':rec,'precision':prec,'average':sum([ac,f1,rec,prec])/4}\n",
    "        return scores\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.classifier.get_params()\n",
    "    \n",
    "    def GridSearch(self,params,X_train,y_train,X_test,y_test,scoring='accuracy',njobs=-1,verbose=False):\n",
    "        \"\"\"\n",
    "        Gridsearch on specified parameter space.\n",
    "        -----------------------------------------\n",
    "        Params:\n",
    "            params(dict): Dictionary ({param:values}) where vaules is a list containing the parameters on\n",
    "                         which the gridsearch will be done.\n",
    "            X_train(array): Input Data for training.\n",
    "            y_train(array): Target values for training.\n",
    "            X_test(array): Input Data for testing.\n",
    "            y_test(array): Target values for testing.\n",
    "            scoring(str): Scoring method for evaluating the model. Can be choosen between: 'accuracy',\n",
    "                         'f1', 'recall', 'precision' and 'average'. (Default = accuracy)\n",
    "            njobs (int): The number of jobs to run in parallel.(Default=-1)\n",
    "        \"\"\"\n",
    "        best_score = 0\n",
    "        params_comb = product(*params.values())\n",
    "        for values in params_comb:\n",
    "            try:\n",
    "                param_dict = {param:value for param,value in zip(params.keys(),values)}\n",
    "\n",
    "                self.set_params(param_dict,njobs)\n",
    "                self.fit(X_train,y_train)\n",
    "                score = self.score(X_test,y_test)[scoring]\n",
    "                if verbose:\n",
    "                    print(param_dict)\n",
    "                    print(f'{scoring} Score:{score}')\n",
    "                if score > best_score:\n",
    "                    best_params = self.get_params()\n",
    "                    best_score = score\n",
    "                    clf = self.classifier\n",
    "                    \n",
    "            except Exception:\n",
    "                continue\n",
    "            \n",
    "        return clf, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(X_train,y_train,X_test,y_test):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    #########################################\n",
    "    ########### KNN CLASSIFIER ##############\n",
    "    #########################################\n",
    "    params = {'n_neighbors':[2,3,4,5,6,7,8,9,10], 'algorithm':['ball_tree','kd_tree'], \n",
    "              'metric':['hamming','minkowski']}\n",
    "    KNN = Pipeline_multioutput(KNeighborsClassifier)\n",
    "    KNN_params = KNN.GridSearch(params,X_train,y_train,X_test,y_test,scoring='average',verbose=0)\n",
    "    KNN_clf = KNN_params[0].fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = KNN_clf.predict(X_test)\n",
    "    print('*'*10,'\\nKNN SCORES\\n','*'*10)\n",
    "    ac = accuracy_score(y_pred,y_test)\n",
    "    f1 = f1_score(y_pred,y_test,average='micro')\n",
    "    rec = recall_score(y_pred,y_test,average='micro')\n",
    "    prec = precision_score(y_pred,y_test,average='micro')\n",
    "    \n",
    "    print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n",
    "    KNN_score = (ac+f1+rec+prec)/4\n",
    "    \n",
    "    #########################################\n",
    "    ############# DECISION TREE #############\n",
    "    #########################################\n",
    "    params = {'criterion':[\"gini\", \"entropy\"],\"splitter\":[\"best\",\"random\"],\n",
    "              'max_features':['log2','auto']}\n",
    "    TREE = Pipeline_multioutput(DecisionTreeClassifier)\n",
    "    TREE_params = TREE.GridSearch(params,X_train,y_train,X_test,y_test,scoring='average')\n",
    "    TREE_clf = TREE_params[0].fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = TREE_clf.predict(X_test)\n",
    "    print('*'*20,'\\nDECISION TREE SCORES\\n','*'*20)\n",
    "    ac = accuracy_score(y_pred,y_test)\n",
    "    f1 = f1_score(y_pred,y_test,average='micro')\n",
    "    rec = recall_score(y_pred,y_test,average='micro')\n",
    "    prec = precision_score(y_pred,y_test,average='micro')\n",
    "\n",
    "    print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n",
    "    TREE_score = (ac+f1+rec+prec)/4\n",
    "    \n",
    "    #########################################\n",
    "    ########## LOGISTIC REGRESSION ##########\n",
    "    #########################################\n",
    "    params = {\"penalty\":['l1','l2','elasticnet'],\"C\":np.linspace(6,60,num=30),\n",
    "                 \"solver\":['newton-cg','lbfgs','sag']}\n",
    "    LOGISTIC = Pipeline_multioutput(LogisticRegression)\n",
    "    LOGISTIC_params = LOGISTIC.GridSearch(params,X_train,y_train,X_test,y_test,scoring='average')\n",
    "    LOGISTIC_clf = LOGISTIC_params[0].fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = LOGISTIC_clf.predict(X_test)\n",
    "    print('*'*30,'\\nLOGISTIC REGRESSION SCORES\\n','*'*30)\n",
    "    ac = accuracy_score(y_pred,y_test)\n",
    "    f1 = f1_score(y_pred,y_test,average='micro')\n",
    "    rec = recall_score(y_pred,y_test,average='micro')\n",
    "    prec = precision_score(y_pred,y_test,average='micro')\n",
    "\n",
    "    print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n",
    "    LOGISTIC_score = (ac+f1+rec+prec)/4\n",
    "    \n",
    "    #///USING RANDOMIZED GRIDSEARCH\n",
    "    \n",
    "    #########################################\n",
    "    ############# RANDOM FOREST #############\n",
    "    #########################################   \n",
    "    params = {\"n_estimators\": scipy.stats.randint(50,200),\n",
    "          'criterion':[\"gini\", \"entropy\"],\n",
    "          \"max_depth\":scipy.stats.randint(1,1000),\n",
    "          'max_features':['log2','auto']}\n",
    "    FOREST = RandomForestClassifier()\n",
    "    FOREST_params = RandomizedSearchCV(FOREST, params)\n",
    "    search = FOREST_params.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = search.predict(X_test)\n",
    "    print('*'*20,'\\nRANDOM FOREST SCORES\\n','*'*20)\n",
    "    ac = accuracy_score(y_pred,y_test)\n",
    "    f1 = f1_score(y_pred,y_test,average='micro')\n",
    "    rec = recall_score(y_pred,y_test,average='micro')\n",
    "    prec = precision_score(y_pred,y_test,average='micro')\n",
    "\n",
    "    print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n",
    "    FOREST_score = (ac+f1+rec+prec)/4\n",
    "    \n",
    "    \n",
    "    #######################################\n",
    "    ########### NEURAL NETWORK ############\n",
    "    #######################################\n",
    "    NN = MLPClassifier(activation='logistic',solver='lbfgs',max_iter=10000)\n",
    "    NN.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = NN.predict(X_test)\n",
    "    print('*'*20,'\\nNEURAL NETWORK SCORES\\n','*'*20)\n",
    "    ac = accuracy_score(y_pred,y_test)\n",
    "    f1 = f1_score(y_pred,y_test,average='micro')\n",
    "    rec = recall_score(y_pred,y_test,average='micro')\n",
    "    prec = precision_score(y_pred,y_test,average='micro')\n",
    "\n",
    "    print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n",
    "    NN_score = (ac+f1+rec+prec)/4\n",
    "    \n",
    "    best_score = max([KNN_score,TREE_score,LOGISTIC_score,FOREST_score,NN_score])\n",
    "    \n",
    "    if best_score == KNN_score:\n",
    "        return KNN_clf\n",
    "    if best_score == TREE_score:\n",
    "        return TREE_clf\n",
    "    if best_score == LOGISTIC_score:\n",
    "        return LOGISTIC_clf\n",
    "    if best_score == FOREST_score:\n",
    "        return search\n",
    "    if best_score == NN_score:\n",
    "        return NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import svm\n",
    "#params = {'penalty':['l1', 'l2'],}\n",
    "#SVM = Pipeline_multioutput(LinearSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 QNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "#### HALF ##########\n",
    "####################\n",
    "\n",
    "CLN_HLT_ALL_50_qnt = pd.read_csv(\"PAN/ALL/CLN_HLT_ALL_50_qnt.csv\",index_col=0)\n",
    "FEATS = list(CLN_HLT_ALL_50_qnt.columns[:8])\n",
    "LABELS = list(CLN_HLT_ALL_50_qnt.columns[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe_vector = ohe.fit_transform(CLN_HLT_ALL_50_qnt[LABELS]).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(CLN_HLT_ALL_50_qnt[FEATS], ohe_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** \n",
      "KNN SCORES\n",
      " **********\n",
      "ACCURACY  : 0.7570592286501377\n",
      "F1 SCORE  : 0.9274113507173148\n",
      "RECALL    : 0.9742654028436019\n",
      "PRECISION : 0.8848570936639119\n",
      "\n",
      "******************** \n",
      "DECISION TREE SCORES\n",
      " ********************\n",
      "ACCURACY  : 0.8573519283746557\n",
      "F1 SCORE  : 0.9832966370945185\n",
      "RECALL    : 0.9830075856432023\n",
      "PRECISION : 0.9835858585858586\n",
      "\n",
      "****************************** \n",
      "LOGISTIC REGRESSION SCORES\n",
      " ******************************\n",
      "ACCURACY  : 0.16520316804407714\n",
      "F1 SCORE  : 0.6340487845696833\n",
      "RECALL    : 0.7606255897528559\n",
      "PRECISION : 0.5435893021120294\n",
      "\n",
      "******************** \n",
      "RANDOM FOREST SCORES\n",
      " ********************\n",
      "ACCURACY  : 0.9527376033057852\n",
      "F1 SCORE  : 0.9905795852719858\n",
      "RECALL    : 0.9914338277566977\n",
      "PRECISION : 0.98972681359045\n",
      "\n",
      "******************** \n",
      "NEURAL NETWORK SCORES\n",
      " ********************\n",
      "ACCURACY  : 0.6902548209366391\n",
      "F1 SCORE  : 0.9211534818657381\n",
      "RECALL    : 0.9357292992687765\n",
      "PRECISION : 0.9070247933884298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#clf.predict(X_test)\n",
    "path_clf_HALF = \"Models/HALF.sav\"\n",
    "if not path.exists(path_clf_HALF):\n",
    "    clf = model_selection(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/HALF.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOREST = clf.best_estimator_\n",
    "dump(FOREST, path_clf_HALF,compress= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 406,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 173,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOREST.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75 QNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLN_HLT_ALL_75_qnt = pd.read_csv(\"PAN/ALL/CLN_HLT_ALL_50_qnt.csv\",index_col=0)\n",
    "FEATS = list(CLN_HLT_ALL_75_qnt.columns[:8])\n",
    "LABELS = list(CLN_HLT_ALL_75_qnt.columns[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe_vector = ohe.fit_transform(CLN_HLT_ALL_75_qnt[LABELS]).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(CLN_HLT_ALL_75_qnt[FEATS], ohe_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = model_selection(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL SELECTION HALF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECTED PARAMETERS FOR RANDOM FOREST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': 406,\n",
    " 'max_features': 'log2',\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 173,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}\n",
    "\n",
    "SAVE = RandomForestClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=406, max_features='log2', n_estimators=173)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** \n",
      "RANDOM FOREST SCORES\n",
      " ********************\n",
      "ACCURACY  : 0.9522210743801653\n",
      "F1 SCORE  : 0.9902279662538143\n",
      "RECALL    : 0.9910605211342502\n",
      "PRECISION : 0.9893968089990818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = SAVE.predict(X_test)\n",
    "print('*'*20,'\\nRANDOM FOREST SCORES\\n','*'*20)\n",
    "ac = accuracy_score(y_pred,y_test)\n",
    "f1 = f1_score(y_pred,y_test,average='micro')\n",
    "rec = recall_score(y_pred,y_test,average='micro')\n",
    "prec = precision_score(y_pred,y_test,average='micro')\n",
    "print(f'ACCURACY  : {ac}\\nF1 SCORE  : {f1}\\nRECALL    : {rec}\\nPRECISION : {prec}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/HALF2.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_clf_HALF = \"Models/HALF2.joblib\"\n",
    "dump(SAVE, path_clf_HALF,compress= 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
