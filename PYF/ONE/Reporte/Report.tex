\documentclass[12pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{{/}}

\title{MoNeT PYF Machine Learning}
\author{Ana Lucía Dueñas Chávez and Juan José Olivera Loyola \thanks{assisted by PhD. Benjamín Valdez (ITESM CQ) in collaboration with PhD. Héctor M. Sanchez (UCB)}}
\date{May 4, 2021}

\begin{document}
\maketitle
\begin{abstract}
In this report we explain the project objectives and steps performed to implement a lightweight ML tool
that approximates the results of a Mosquito population simulator.
\end{abstract}

\section{Introduction}
Mosquitos often carry diseases such as Dengue, Malaria, etc. That's why effort and economic investment
has been placed in researching management of species' populations via introduction of gentically modified
organisms who can surpress disease propagation. However, such actions require extensive knowledge
and obtaining it through real test and error experiments is both infeasable and dangerous.

MoNeT (Mosquito Networks Taskforce) was created to develop computer tools that are capable of simulating 
mosquito population dynamics, movement and genetics aiding biologists to solve for the right variables.
One of it's key reaseach lines is eliminating mosquitos in a population network of mosquitos in the
French Polynesia Island. MoNeT's simulator is capable of producing population dynamics outcomes.
However, it's computationally expensive, and during interdisciplinary meetings,
it's common to speculate on many possible configuration out of the air. A more lightweight tool is needed
to give immediate likely estimations for hypothesized configurations.

Machine Learning techniques have proven to be a general powerful tool for estimating functions and
statistical distrbution spaces given large amounts of sample data and training time. 
Besides being universal approximators, ML models take short computational time for making arbitrary estimations
and take very few memory space in comparison to the whole dataset they are approximating. 
Thus, ML techniques are a great technology to build
a quick estimation tool for experiment outcomes from prior data.
\section{Objective}
\subsubsection{Main Objective}
To produce a lightweight ML tool that can estimate elimination probability and time window results
of release experiments of genetically modified mosquitos.

\subsubsection{Subobjectives}
\begin{itemize}
    \item Interpretability: Understanding why a classification was made by the model is expected. Also, some confidence on the prediction is desireable.
    \item Framework Compliant: Prefereably built around scikit-learn. Has to accept numpy arrays and save and load models with joblib.
    \item Flexible Resolution: Model can be readjusted to a different dataset; same experiment but different zone of interest.
\end{itemize}

\section{Data Exploration}
\subsection{Features}
We begin by describing our dataset. Each experiment run is configured by 5 parameters:
\begin{itemize}
    \item (\emph{pop}) Population size per node % Entender bien esto porque lo maximo es 20, y 20 mosquitos suena a muy poco en ecosistema real
    \item (\emph{ren}) Number of weekly releases
    \item (\emph{res}) Release size % Que es fraccion de la poblacion estable? O sea originalmente
    % res es un numero entre [0,1]? La poblacion estable es la de pop? U otra poblacion, la de los mosquitos modificados en el lab?
    \item (\emph{mad}) Adult lifespan reduction % Este es un factor de proporcion dado por el gen, o es la cantidad de mosquitos esperados a reducir?
    \item (\emph{mat}) Male mating reduction    % Misma duda
\end{itemize}
So, we have a feature describing the environment where the mosquitos are to be released, 2 features describing a modification
on the mosquito organisms and finally 2 features to describe releasing modes.
\subsection{Target Variables}
MoNeT simulator outcomes can be analyzed with several metrics for each experiment configuration.
From these we try to predict two:
\begin{itemize}
    \item (\emph{POE}) Probability of Elimination
    \item (\emph{$WOP_{threshold}$}) Window of time that wild gene population is below a specific threshold.
\end{itemize}
Figure \ref{img:randomsimoutcomes}. shows several outcome instances by the simulator for the same configuration.
In the vertical axis we have the proportion of the population of mosquitos with the wild gene we are trying to surpress.
On the horizontal axis we have time in years. Each line represents a different outcome in the long run. 
We can observer for this configuration,
that all outcomes at first reduce significantly the target population the first year
, however, the population reestablishes in the following years for most of them.

\begin{figure}[h]
    \centering
    \includegraphics{randomsimoutcomes.jpg}
    \caption{Different possible outcomes for a single arbitrary experiment configuration.}
    \label{img:randomsimoutcomes}
\end{figure}

\subsection{Dataset Organization}
The dataset used for this project contains the results of 16,000 runs. However, each experiment run
has several random factors so it commonly generates mulitple outcomes as shown in Figure \ref{img:randomsimoutcomes}.
To account for this, simulation proportions are grouped by a worst case bound result and saved
under a file with the specific percentile associated (50\%, 75\%, 90\%). For example, let's say we 
read a Probability of Elimination Outcome ($POE_i$) of 0.83 for features $x_i$=$(pop=20, ren=8, res=10, mat=30, mad=20)$ for
the 50\% file. 
This means that 50\% of the simulations under this specific configuration resulted at least in a 70\% probability of elimination.
Then, if we were to see a \emph{POE} value of 0.71 for the same configuration on the 90\%, this would mean that configuration $x_i$,
most probable outcome bad, as the metric got lower when taking into account the majority of the simulation results.
Also, as more simulations are taking into consideration, the variance is expected to be lowest for percentil 50 and highest for percentil 90.

\subsection{Histograms}
\subsubsection{Features}
After plotting each feature variable on it's own histogram in Fig. \ref{fig:feat_histograms}
we can see that all values are integer and some values have more presence overall.
After couting the frequency of each unique value for each feature we confirm that to 
produce the dataset, certain values were given more weight by repeating it more times
in simulation runs. For \emph{pop}, \emph{ren} and \emph{res}, just a few values had
majority weight. However, both \emph{mad} and \emph{mat} shared same importance across
multiples of 5 from $[0-50]$.
\begin{figure}[h]
    \centering
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_i_pop.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_i_ren.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_i_res.png}}
    \hfil
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_i_mat.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_i_mad.png}} 
    \caption{(a) pop (b) ren (c) res (d) mad (e) mat}
    \label{fig:feat_histograms}
\end{figure}
\subsubsection{Targets}
Our targets are computed from aggregating multiple runs per configuration
and are divided into 3 quantiles: 50\%, 75\%, 90\%. We then will plot the
each target variable distribution for each quantile.
\begin{figure}[h]
    \centering
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_POE_50.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_POE_75.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{hist_POE_90.png}}
    \hfil 
    \caption{(a) POE 50\% (b) POE 75\% (c) POE 90\%}
    \label{fig:target_histopoe}
\end{figure}

We find from Fig. \ref{fig:target_histopoe} that probability of elimination
is the same regardless the quantile matrics we are looking at.

\begin{figure}[h]
    \centering
    \subfloat[]{\includegraphics[width=0.98\textwidth]{hist_wop_005.jpg}} 
    \hfil
    \subfloat[]{\includegraphics[width=0.98\textwidth]{hist_wop_005.jpg}} 
    \hfil
    \subfloat[]{\includegraphics[width=0.98\textwidth]{hist_wop_005.jpg}} 
    \hfil
    \subfloat[]{\includegraphics[width=0.98\textwidth]{hist_wop_005.jpg}} 
    \hfil
    \subfloat[]{\includegraphics[width=0.98\textwidth]{hist_wop_005.jpg}} 
    \hfil
    \subfloat[]{\includegraphics[width=0.98\textwidth]{hist_wop_005.jpg}} 
    \hfil 
    \caption{(a) ${WOP_{0.05}}$, (b) ${WOP_{0.10}}$, (c) ${WOP_{0.50}}$, (d) ${WOP_{0.75}}$, (e) ${WOP_{0.90}}$, (f) ${WOP_{0.95}}$}
    \label{fig:target_histowop}
\end{figure}


\subsection{Correlations}
\begin{figure}[h]
    \centering
    \subfloat[]{\includegraphics[width=0.32\textwidth]{corr_i_pop_POE.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{corr_i_ren_POE.png}} 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{corr_i_res_POE.png}}
    \hfil 
    \subfloat[]{\includegraphics[width=0.32\textwidth]{corr_i_mat_POE.png}}
    \subfloat[]{\includegraphics[width=0.32\textwidth]{corr_i_mad_POE.png}}
    \hfil 
    \caption{(a) $pop - POE$ (b) $ren-POE$ (c) $res-POE$ (d) $mad-POE$ (e) $mat-POE$}
    \label{fig:corr_poe}
\end{figure}


\subsection{Discretazing Target Variables}
The results of this model will be used during brainstorm meetings and
it are meant to loosely evaluate if some hypothesis are reasonable to explore.
For that, we are expected to deliver categorical results. Instead of 
a real interval of values, we ought to give ['LOW', 'MID', 'HIGH'] labels.

To make easier our exploration analysis and training we discretized every target variable.
We did so by dividing our target variable' ranges into 3 intervals all the points that
lay within the same interval get assigned the same label. However, we did not uniformly 
divide the ranges to obtain the intervals, instead, we decided the boundaries from what
we observed in the target histograms.
For the data exploration we decided on the following intervals:
\begin{figure}[h]
    \begin{center}
    \begin{tabular}{c c c c}
            \hline
            Target & Low & Mid & High \\
            \hline\hline
            POE & $[0-0.6)$ & $[0.6-0.85)$ & $[0.85-1)$ \\
            $WOP_i$ & $[0-250)$ & $[250-1500)$ & $[1500-2000)$ \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Discretization intervals for data exploration}
    \label{table:de_discreteintervals}
\end{figure}
\subsection{Understanding POE outcomes through decision trees}
Our feature space is composed of discrete integer data and a low
amount of unique values per features. Nonetheless, our relationships
are far from linear, making it hard to analyze manually. At this point
we tried to use a Decision Tree and analyze its' decision conditions to
understand better the data.


\subsection{Understanding WOP outcomes throught 3D plotting}




%% Aqui va el histograma de POW y el de l




\section{Model Selection}
\subsection{Evaluating multiple configurations}
\subsection{Tree Results}
\subsection{KNN Results}
\subsection{NN Results}
\section{Pipeline Integration}
\section{Discussion}
\begin{itemize}
    \item Weight of specifics values for each feature might heavily influnce model training. Would be nice to verify results in interpolated points.
\end{itemize}
\section{Conclusion}
\section{References}
\end{document}